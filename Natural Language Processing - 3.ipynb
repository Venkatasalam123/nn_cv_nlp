{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "import string\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('Sarcasm_Headlines_Dataset.json', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['is_sarcastic', 'headline', 'article_link'])\n",
    "for row in data:\n",
    "    df = pd.concat([df, pd.json_normalize(json.loads(row))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  is_sarcastic                                           headline  \\\n",
       "0            1  thirtysomething scientists unveil doomsday clo...   \n",
       "1            0  dem rep. totally nails why congress is falling...   \n",
       "2            0  eat your veggies: 9 deliciously different recipes   \n",
       "3            1  inclement weather prevents liar from getting t...   \n",
       "4            1  mother comes pretty close to using word 'strea...   \n",
       "\n",
       "                                        article_link  \n",
       "0  https://www.theonion.com/thirtysomething-scien...  \n",
       "1  https://www.huffingtonpost.com/entry/donna-edw...  \n",
       "2  https://www.huffingtonpost.com/entry/eat-your-...  \n",
       "3  https://local.theonion.com/inclement-weather-p...  \n",
       "4  https://www.theonion.com/mother-comes-pretty-c...  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can drop the link column for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['article_link'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28619, 2)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for the ratio os sarcastic headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14985\n",
       "1    13634\n",
       "Name: is_sarcastic, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_sarcastic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_sarcastic    0\n",
       "headline        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  is_sarcastic                                           headline\n",
       "0            1  thirtysomething scientists unveil doomsday clo...\n",
       "1            0  dem rep. totally nails why congress is falling...\n",
       "2            0  eat your veggies: 9 deliciously different recipes\n",
       "3            1  inclement weather prevents liar from getting t...\n",
       "4            1  mother comes pretty close to using word 'strea..."
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(data):\n",
    "    data['headline without stopwords'] = data['headline'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "    return data\n",
    "\n",
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>','',string)\n",
    "    return result\n",
    "    \n",
    "data_without_stopwords = remove_stopwords(df)\n",
    "data_without_stopwords['clean_headline']= data_without_stopwords['headline without stopwords'].apply(lambda cw : remove_tags(cw))\n",
    "data_without_stopwords['clean_headline'] = data_without_stopwords['clean_headline'].str.replace('[{}]'.format(string.punctuation), ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>headline without stopwords</th>\n",
       "      <th>clean_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep totally nails why congress is falling ...</td>\n",
       "      <td>dem rep totally nails congress falling short g...</td>\n",
       "      <td>dem rep totally nails congress falling short g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies 9 deliciously different recipes</td>\n",
       "      <td>eat veggies 9 deliciously different recipes</td>\n",
       "      <td>eat veggies 9 deliciously different recipes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>inclement weather prevents liar getting work</td>\n",
       "      <td>inclement weather prevents liar getting work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word stream...</td>\n",
       "      <td>mother comes pretty close using word streaming...</td>\n",
       "      <td>mother comes pretty close using word streaming...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  is_sarcastic                                           headline  \\\n",
       "0            1  thirtysomething scientists unveil doomsday clo...   \n",
       "1            0  dem rep totally nails why congress is falling ...   \n",
       "2            0   eat your veggies 9 deliciously different recipes   \n",
       "3            1  inclement weather prevents liar from getting t...   \n",
       "4            1  mother comes pretty close to using word stream...   \n",
       "\n",
       "                          headline without stopwords  \\\n",
       "0  thirtysomething scientists unveil doomsday clo...   \n",
       "1  dem rep totally nails congress falling short g...   \n",
       "2        eat veggies 9 deliciously different recipes   \n",
       "3       inclement weather prevents liar getting work   \n",
       "4  mother comes pretty close using word streaming...   \n",
       "\n",
       "                                      clean_headline  \n",
       "0  thirtysomething scientists unveil doomsday clo...  \n",
       "1  dem rep totally nails congress falling short g...  \n",
       "2        eat veggies 9 deliciously different recipes  \n",
       "3       inclement weather prevents liar getting work  \n",
       "4  mother comes pretty close using word streaming...  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_without_stopwords.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the length of each sentence after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_without_stopwords['Length'] = data_without_stopwords['clean_headline'].apply(lambda x : len(x.split(' ')))\n",
    "max_length = data_without_stopwords['Length'].max()\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabSize = 2000\n",
    "tokenizer = Tokenizer(num_words=vocabSize, split=' ')\n",
    "tokenizer.fit_on_texts(data_without_stopwords['clean_headline'].values)\n",
    "X = tokenizer.texts_to_sequences(data_without_stopwords['clean_headline'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24326, 35) (24326, 2)\n",
      "(4293, 35) (4293, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = pd.get_dummies(data_without_stopwords['is_sarcastic']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.15, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 35, 128)           256000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_14 (Spatia (None, 35, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, 392)               509600    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 786       \n",
      "=================================================================\n",
      "Total params: 766,386\n",
      "Trainable params: 766,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional\n",
    "\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabSize, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(Bidirectional(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "381/381 - 186s - loss: 0.5499 - accuracy: 0.7043\n",
      "Epoch 2/5\n",
      "381/381 - 126s - loss: 0.4439 - accuracy: 0.7847\n",
      "Epoch 3/5\n",
      "381/381 - 127s - loss: 0.4153 - accuracy: 0.8025\n",
      "Epoch 4/5\n",
      "381/381 - 365s - loss: 0.3936 - accuracy: 0.8111\n",
      "Epoch 5/5\n",
      "381/381 - 462s - loss: 0.3754 - accuracy: 0.8210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1432231d0d0>"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "model.fit(X_train, Y_train, epochs = 5, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 29s 213ms/step - loss: 0.4669 - accuracy: 0.7734\n",
      "Model loss is:  0.46688002347946167\n",
      "Model accuracy is:  0.7733519673347473\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, Y_test)\n",
    "print('Model loss is: ', loss)\n",
    "print('Model accuracy is: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline = data_without_stopwords['clean_headline']\n",
    "\n",
    "headline_list = []\n",
    "for i in range(len(headline)):\n",
    "    headline_list.append(headline[i])\n",
    "\n",
    "sentiment = data_without_stopwords['is_sarcastic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split to build a bidirectional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(list(sentiment))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(headline_list, y, test_size=0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "words_to_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove embeddings and indexing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glove.6B.300d.txt', 'r', encoding='UTF-8') as f:\n",
    "    words = set()\n",
    "    word_to_vec_map = {}\n",
    "    for line in f:\n",
    "        w_line = line.split()\n",
    "        curr_word = w_line[0]\n",
    "        word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
    "maxLen = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(words_to_index)\n",
    "embed_vector_len = word_to_vec_map['test'].shape[0]\n",
    "\n",
    "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
    "\n",
    "for word, index in words_to_index.items():\n",
    "    embedding_vector = word_to_vec_map.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        emb_matrix[index-1, :] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 150, 300)          7951200   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_16 (Spatia (None, 150, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_14 (Bidirectio (None, 150, 256)          439296    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 150, 1)            257       \n",
      "=================================================================\n",
      "Total params: 8,390,753\n",
      "Trainable params: 439,553\n",
      "Non-trainable params: 7,951,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(150))\n",
    "model.add(Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "358/358 [==============================] - 256s 715ms/step - loss: 0.6971 - accuracy: 0.5110\n",
      "Epoch 2/6\n",
      "358/358 [==============================] - 256s 716ms/step - loss: 0.6914 - accuracy: 0.5244\n",
      "Epoch 3/6\n",
      "358/358 [==============================] - 256s 714ms/step - loss: 0.6592 - accuracy: 0.6107\n",
      "Epoch 4/6\n",
      "358/358 [==============================] - 256s 715ms/step - loss: 0.6348 - accuracy: 0.6404\n",
      "Epoch 5/6\n",
      "358/358 [==============================] - 256s 716ms/step - loss: 0.5963 - accuracy: 0.6775\n",
      "Epoch 6/6\n",
      "358/358 [==============================] - 256s 716ms/step - loss: 0.5580 - accuracy: 0.7078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14308a4cac0>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train, batch_size=64, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 78s 433ms/step - loss: 0.5503 - accuracy: 0.7137\n",
      "Model loss is:  0.5503225922584534\n",
      "Model accuracy is:  0.7136548757553101\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test_indices, Y_test)\n",
    "print('Model loss is: ', loss)\n",
    "print('Model accuracy is: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarcastic\n"
     ]
    }
   ],
   "source": [
    "n = np.random.randint(0,5000)\n",
    "\n",
    "if preds[n].any() > 0.5:\n",
    "    print('Sarcastic')\n",
    "else: \n",
    "    print('Not Sarcastic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

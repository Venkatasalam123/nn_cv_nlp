{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Venkat\n",
      "[nltk_data]     Karthi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('punkt')\n",
    "from nltk.chat.util import Chat, reflections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import random\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Dropout,BatchNormalization,Activation,Flatten\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('GL Bot.json') as file:\n",
    "    corpus = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'tag': 'Intro',\n",
       "   'patterns': ['hi',\n",
       "    'how are you',\n",
       "    'You How',\n",
       "    'is anyone there',\n",
       "    'hello',\n",
       "    'whats up',\n",
       "    'What Doing',\n",
       "    'hey',\n",
       "    'yo',\n",
       "    'listen',\n",
       "    'hie',\n",
       "    'Are you there',\n",
       "    'please help me',\n",
       "    'i am learner from',\n",
       "    'i belong to',\n",
       "    'aiml batch',\n",
       "    'aifl batch',\n",
       "    'i am from',\n",
       "    'my pm is',\n",
       "    'blended',\n",
       "    'online',\n",
       "    'i am from',\n",
       "    'hey ya',\n",
       "    'talking to you for first time'],\n",
       "   'responses': ['Hello! how can i help you ?'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'Exit',\n",
       "   'patterns': ['thank you',\n",
       "    'thanks',\n",
       "    'cya',\n",
       "    'see you',\n",
       "    'later',\n",
       "    'see you later',\n",
       "    'goodbye',\n",
       "    'i am leaving',\n",
       "    'have a Good day',\n",
       "    'you helped me',\n",
       "    'thanks a lot',\n",
       "    'thanks a ton',\n",
       "    'you are the best',\n",
       "    'great help',\n",
       "    'too good',\n",
       "    'tata',\n",
       "    'Bubye',\n",
       "    'Thank you so much for your help',\n",
       "    'Thank god You helped me',\n",
       "    'you are a good learning buddy'],\n",
       "   'responses': ['I hope I was able to assist you, Good Bye'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'Olympus',\n",
       "   'patterns': ['olympus',\n",
       "    'explain me how olympus works',\n",
       "    'I am not able to understand olympus',\n",
       "    'olympus window not working',\n",
       "    'no access to olympus',\n",
       "    'unable to see link in olympus',\n",
       "    'no link visible on olympus',\n",
       "    'whom to contact for olympus',\n",
       "    'lot of problem with olympus',\n",
       "    'olypus is not a good tool',\n",
       "    'lot of problems with olympus',\n",
       "    'how to use olympus',\n",
       "    'Where to access Olympus',\n",
       "    'Is olympus server down',\n",
       "    'teach me olympus'],\n",
       "   'responses': ['Link: Olympus wiki'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'SL',\n",
       "   'patterns': ['i am not able to understand svm',\n",
       "    'explain me how machine learning works',\n",
       "    'i am not able to understand naive bayes',\n",
       "    'i am not able to understand logistic regression',\n",
       "    'i am not able to understand ensemble techniques',\n",
       "    'i am not able to understand knn',\n",
       "    'i am not able to understand knn imputer',\n",
       "    'i am not able to understand cross validation',\n",
       "    'i am not able to understand boosting',\n",
       "    'i am not able to understand random forest',\n",
       "    'i am not able to understand ada boosting',\n",
       "    'i am not able to understand gradient boosting',\n",
       "    'i am not able to understand bagging',\n",
       "    'What is supervised Learning',\n",
       "    'What is unsupervised Learning',\n",
       "    'Where to start for Machine Learning',\n",
       "    'tuning',\n",
       "    'machine learning',\n",
       "    'ML',\n",
       "    'SL',\n",
       "    'supervised learning',\n",
       "    'knn',\n",
       "    'logistic regression',\n",
       "    'regression',\n",
       "    'classification',\n",
       "    'naive bayes',\n",
       "    'nb',\n",
       "    'ensemble techniques',\n",
       "    'bagging',\n",
       "    'boosting',\n",
       "    'ada boosting',\n",
       "    'ada',\n",
       "    'gradient boosting',\n",
       "    'hyper parameters'],\n",
       "   'responses': ['Link: Machine Learning wiki '],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'NN',\n",
       "   'patterns': ['what is deep learning',\n",
       "    'unable to understand deep learning',\n",
       "    'explain me how deep learning works',\n",
       "    'i am not able to understand deep learning',\n",
       "    'not able to understand neural nets',\n",
       "    'very diffult to understand neural nets',\n",
       "    'unable to understand neural nets',\n",
       "    'ann',\n",
       "    'artificial intelligence',\n",
       "    'artificial neural networks',\n",
       "    'weights',\n",
       "    'activation function',\n",
       "    'hidden layers',\n",
       "    'softmax',\n",
       "    'sigmoid',\n",
       "    'relu',\n",
       "    'batch size',\n",
       "    'Cnn',\n",
       "    'Computer Vision',\n",
       "    'otimizer',\n",
       "    'forward propagation',\n",
       "    'backward propagation',\n",
       "    'epochs',\n",
       "    'epoch',\n",
       "    'what is an epoch',\n",
       "    'adam',\n",
       "    'sgd'],\n",
       "   'responses': ['Link: Neural Nets wiki'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'Bot',\n",
       "   'patterns': ['what is your name',\n",
       "    'who are you',\n",
       "    'name please',\n",
       "    'Say your details',\n",
       "    'What is your work timings',\n",
       "    'when are your hours of opertions',\n",
       "    'what are your working hours',\n",
       "    'hours of operation',\n",
       "    'working hours',\n",
       "    'hours'],\n",
       "   'responses': ['I am your virtual learning assistant'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'Profane',\n",
       "   'patterns': ['what the hell',\n",
       "    'bloody stupid bot',\n",
       "    'shut up',\n",
       "    'Worst bot',\n",
       "    'Cant you understand idiot',\n",
       "    'do you think you are very smart',\n",
       "    'screw you',\n",
       "    'i hate you',\n",
       "    'you are stupid',\n",
       "    'jerk',\n",
       "    'you are a joke',\n",
       "    'useless piece of shit'],\n",
       "   'responses': ['Please use respectful words'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'Ticket',\n",
       "   'patterns': ['my problem is not solved',\n",
       "    'you did not help me',\n",
       "    'not a good solution',\n",
       "    'I need more support',\n",
       "    'bad solution',\n",
       "    'not good solution',\n",
       "    'no help',\n",
       "    'wasted my time',\n",
       "    'useless bot',\n",
       "    'create a ticket'],\n",
       "   'responses': ['Tarnsferring the request to your PM'],\n",
       "   'context_set': ''}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert into DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df= pd.DataFrame(columns = ['patterns', 'tag', 'responses'])\n",
    "for intent in corpus['intents']:\n",
    "    df = pd.DataFrame(columns = ['patterns', 'tag'])\n",
    "    df['patterns'] = intent['patterns']\n",
    "    df['responses'] = intent['responses'][0]\n",
    "    df['tag'] = intent['tag']\n",
    "    final_df = final_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patterns</th>\n",
       "      <th>tag</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi</td>\n",
       "      <td>Intro</td>\n",
       "      <td>Hello! how can i help you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how are you</td>\n",
       "      <td>Intro</td>\n",
       "      <td>Hello! how can i help you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You How</td>\n",
       "      <td>Intro</td>\n",
       "      <td>Hello! how can i help you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is anyone there</td>\n",
       "      <td>Intro</td>\n",
       "      <td>Hello! how can i help you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hello</td>\n",
       "      <td>Intro</td>\n",
       "      <td>Hello! how can i help you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>not good solution</td>\n",
       "      <td>Ticket</td>\n",
       "      <td>Tarnsferring the request to your PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no help</td>\n",
       "      <td>Ticket</td>\n",
       "      <td>Tarnsferring the request to your PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wasted my time</td>\n",
       "      <td>Ticket</td>\n",
       "      <td>Tarnsferring the request to your PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>useless bot</td>\n",
       "      <td>Ticket</td>\n",
       "      <td>Tarnsferring the request to your PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>create a ticket</td>\n",
       "      <td>Ticket</td>\n",
       "      <td>Tarnsferring the request to your PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             patterns     tag                            responses\n",
       "0                  hi   Intro          Hello! how can i help you ?\n",
       "1         how are you   Intro          Hello! how can i help you ?\n",
       "2             You How   Intro          Hello! how can i help you ?\n",
       "3     is anyone there   Intro          Hello! how can i help you ?\n",
       "4               hello   Intro          Hello! how can i help you ?\n",
       "..                ...     ...                                  ...\n",
       "5   not good solution  Ticket  Tarnsferring the request to your PM\n",
       "6             no help  Ticket  Tarnsferring the request to your PM\n",
       "7      wasted my time  Ticket  Tarnsferring the request to your PM\n",
       "8         useless bot  Ticket  Tarnsferring the request to your PM\n",
       "9     create a ticket  Ticket  Tarnsferring the request to your PM\n",
       "\n",
       "[152 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training utterances: 129\n",
      "Validation utterances: 23\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    final_df['patterns'].values, final_df['tag'].values, \n",
    "    test_size=0.15, random_state=0)\n",
    "print('Training utterances: {}'.format(X_train.shape[0]))\n",
    "print('Validation utterances: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf approach for NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<129x167 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 398 stored elements in Compressed Sparse Row format>,\n",
       " <23x167 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 45 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "X_train_vec = vectorizer.transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "X_train_vec, X_test_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build NB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43478260869565216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vec, y_train)\n",
    "pred = clf.predict(X_test_vec)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['very diffult to understand neural nets', 'olympus',\n",
       "       'i am not able to understand logistic regression', 'thank you',\n",
       "       'artificial neural networks', 'great help', 'classification',\n",
       "       'hey', 'forward propagation', 'whom to contact for olympus',\n",
       "       'Bubye', 'hours of operation', 'Worst bot', 'cya',\n",
       "       'artificial intelligence', 'wasted my time', 'relu',\n",
       "       'lot of problems with olympus', 'batch size', 'you helped me',\n",
       "       'screw you', 'i am not able to understand naive bayes',\n",
       "       'working hours'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NN', 'Olympus', 'SL', 'Exit', 'NN', 'Exit', 'SL', 'Intro', 'NN',\n",
       "       'Olympus', 'Exit', 'Bot', 'Profane', 'Exit', 'NN', 'Ticket', 'NN',\n",
       "       'Olympus', 'NN', 'Exit', 'Profane', 'SL', 'Bot'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NN', 'Olympus', 'SL', 'Exit', 'NN', 'Intro', 'SL', 'Intro', 'NN',\n",
       "       'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'Intro', 'SL', 'Olympus',\n",
       "       'Intro', 'Intro', 'Intro', 'SL', 'SL'], dtype='<U7')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat utility function using NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOT: Hello! how can i help you ?\n"
     ]
    }
   ],
   "source": [
    "val = np.array(['Hi'])\n",
    "val = vectorizer.transform(val)\n",
    "print(\"BOT:\",list(final_df[final_df['tag'] == clf.predict(val)[0]]['responses'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print('Hi This is Chitti!. How can I help you?')\n",
    "    while True:\n",
    "        inp = input(\"You:\")    \n",
    "        if inp.lower() == 'quit':\n",
    "            break\n",
    "        else:\n",
    "            val = np.array([inp])\n",
    "            val = vectorizer.transform(val)\n",
    "            print(\"Chitti:\",list(final_df[final_df['tag'] == clf.predict(val)[0]]['responses'])[0])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi This is Chitti!. How can I help you?\n",
      "You:Hi\n",
      "Chitti: Hello! how can i help you ?\n",
      "You:whats up\n",
      "Chitti: Hello! how can i help you ?\n",
      "You:talking to you for first time\n",
      "Chitti: Hello! how can i help you ?\n",
      "You:thank you\n",
      "Chitti: I hope I was able to assist you, Good Bye\n",
      "You:you are the best\n",
      "Chitti: I hope I was able to assist you, Good Bye\n",
      "You:explain me how olympus works\n",
      "Chitti: Link: Olympus wiki\n",
      "You:lot of problem with olympus\n",
      "Chitti: Link: Olympus wiki\n",
      "You:i am not able to understand knn\n",
      "Chitti: Link: Machine Learning wiki \n",
      "You:ML\n",
      "Chitti: Link: Machine Learning wiki \n",
      "You:gradient boosting\n",
      "Chitti: Link: Machine Learning wiki \n",
      "You:artificial intelligence\n",
      "Chitti: Link: Machine Learning wiki \n",
      "You:unable to understand deep learning\n",
      "Chitti: Link: Neural Nets wiki\n",
      "You:Computer visin\n",
      "Chitti: Link: Neural Nets wiki\n",
      "You:name please\n",
      "Chitti: Hello! how can i help you ?\n",
      "You:what is your name\n",
      "Chitti: I am your virtual learning assistant\n",
      "You:screw you\n",
      "Chitti: Hello! how can i help you ?\n",
      "You:what the hell\n",
      "Chitti: Link: Machine Learning wiki \n",
      "You:Worst bot\n",
      "Chitti: Link: Machine Learning wiki \n",
      "You:my problem is not solved\n",
      "Chitti: Link: Machine Learning wiki \n",
      "You:I need more support\n",
      "Chitti: Link: Machine Learning wiki \n",
      "You:quit\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Approach (Best One)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = []\n",
    "L = []\n",
    "doc_x = []\n",
    "doc_y = []\n",
    "\n",
    "for intent in corpus['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        w_temp = nltk.word_tokenize(pattern)\n",
    "        W.extend(w_temp)\n",
    "        doc_x.append(w_temp)\n",
    "        doc_y.append(intent['tag'])\n",
    "    if intent['tag'] not in L:\n",
    "        L.append(intent['tag'])\n",
    "        \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "W = [lemmatizer.lemmatize(w.lower()) for w in W]\n",
    "W = sorted(list(set(W)))\n",
    "L = sorted(L)\n",
    "\n",
    "Train = []\n",
    "Target = []\n",
    "out_empty = [0 for _ in range(len(L))]\n",
    "\n",
    "for x, doc in enumerate(doc_x):\n",
    "    bag = []\n",
    "    \n",
    "    w_temp = [lemmatizer.lemmatize(w.lower()) for w in doc]\n",
    "    \n",
    "    for w in W:\n",
    "        if w in w_temp:\n",
    "            bag.append(1)\n",
    "        else:\n",
    "            bag.append(0)\n",
    "            \n",
    "    output_row = out_empty[:]\n",
    "    output_row[L.index(doc_y[x])] = 1\n",
    "    \n",
    "    Train.append(bag)\n",
    "    Target.append(output_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.1014 - accuracy: 0.0987\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.0765 - accuracy: 0.1711\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 2.0686 - accuracy: 0.1645\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.9896 - accuracy: 0.2961\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.9717 - accuracy: 0.2237\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.9007 - accuracy: 0.3158\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.8782 - accuracy: 0.3684\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.7855 - accuracy: 0.3816\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.7546 - accuracy: 0.3026\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.6948 - accuracy: 0.4079\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.6370 - accuracy: 0.3750\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.5846 - accuracy: 0.4737\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.5167 - accuracy: 0.4934\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.4965 - accuracy: 0.4605\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.4696 - accuracy: 0.5066\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.4560 - accuracy: 0.5263\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.3589 - accuracy: 0.5197\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2615 - accuracy: 0.5724\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2978 - accuracy: 0.5658\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.2330 - accuracy: 0.6316\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1812 - accuracy: 0.5658\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.1035 - accuracy: 0.6382\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9717 - accuracy: 0.7368\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0206 - accuracy: 0.6513\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0803 - accuracy: 0.6316\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0070 - accuracy: 0.6711\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8698 - accuracy: 0.7171\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7967 - accuracy: 0.7697\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8211 - accuracy: 0.7303\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7806 - accuracy: 0.7434\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7518 - accuracy: 0.7895\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.8355\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7196 - accuracy: 0.7829\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.8487\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.8289\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6731 - accuracy: 0.8026\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.8158\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.8684\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.8355\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.8882\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.8092\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8618\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.8553\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.9079\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8882\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8750\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8882\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.9342\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8882\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.9013\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.9145\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8684\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8882\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8882\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.9211\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.9211\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.9211\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.9145\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.9408\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.9342\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.9013\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.9013\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1604 - accuracy: 0.9934\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9474\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2160 - accuracy: 0.9737\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.9013\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9408\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.9276\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.9408\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2332 - accuracy: 0.9342\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2021 - accuracy: 0.9539\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2294 - accuracy: 0.9539\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.8882\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.9342\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.9474\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9539\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1565 - accuracy: 0.9671\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2038 - accuracy: 0.9408\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9474\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9605\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9408\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9342\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9474\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9737\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9737\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.9408\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9474\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9408\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1662 - accuracy: 0.9474\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.9539\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1691 - accuracy: 0.9408\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9868\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9803\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9671\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.9737\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1554 - accuracy: 0.9605\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.9803\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.9803\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9539\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4cd51b730>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim = len(Train[0]), activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(Target[0]), activation = 'softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(Train, Target, epochs=100, batch_size=5, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(inp, W):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    inp_x = []\n",
    "    Test = []\n",
    "    w_temp = nltk.word_tokenize(inp)\n",
    "    inp_x.append(w_temp)\n",
    "    for x, doc in enumerate(inp_x):\n",
    "        bag = []   \n",
    "        w_temp = [lemmatizer.lemmatize(w.lower()) for w in doc]\n",
    "        for w in W:\n",
    "            if w in w_temp:\n",
    "                bag.append(1)\n",
    "            else:\n",
    "                bag.append(0)\n",
    "\n",
    "        Test.append(bag)\n",
    "    return Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print('Hi This is Chitti!. How can I help you?')\n",
    "    while True:\n",
    "        inp = input(\"You:\")    \n",
    "        if inp.lower() == 'quit':\n",
    "            break\n",
    "        results = model.predict(bag_of_words(inp, W))\n",
    "        results_index = np.argmax(results)\n",
    "\n",
    "        tag = L[results_index]\n",
    "\n",
    "        for tg in corpus[\"intents\"]:\n",
    "            if tg['tag'] == tag:\n",
    "                responses = tg['responses']\n",
    "                \n",
    "        print(responses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi This is Chitti!. How can I help you?\n",
      "You:hello\n",
      "Hello! how can i help you ?\n",
      "You:how are you\n",
      "Hello! how can i help you ?\n",
      "You:Are you there\n",
      "Hello! how can i help you ?\n",
      "You:talking to you for first time\n",
      "Hello! how can i help you ?\n",
      "You:thank you\n",
      "I hope I was able to assist you, Good Bye\n",
      "You:Bubye\n",
      "I hope I was able to assist you, Good Bye\n",
      "You:explain me how olympus works\n",
      "Link: Olympus wiki\n",
      "You:lot of problems with olympus\n",
      "Link: Olympus wiki\n",
      "You:explain me how machine learning works\n",
      "Link: Machine Learning wiki \n",
      "You:tuning\n",
      "Link: Machine Learning wiki \n",
      "You:gradient\n",
      "Link: Machine Learning wiki \n",
      "You:artificial intelligence\n",
      "Link: Neural Nets wiki\n",
      "You:Computer visin\n",
      "Link: Neural Nets wiki\n",
      "You:adam\n",
      "Link: Neural Nets wiki\n",
      "You:Say your details\n",
      "I am your virtual learning assistant\n",
      "You:what the hell\n",
      "Please use respectful words\n",
      "You:screw you\n",
      "Please use respectful words\n",
      "You:jerk\n",
      "Please use respectful words\n",
      "You:my problem is not solved\n",
      "Tarnsferring the request to your PM\n",
      "You:bad solution\n",
      "Tarnsferring the request to your PM\n",
      "You:not solved \n",
      "Tarnsferring the request to your PM\n",
      "You:hate you\n",
      "Please use respectful words\n",
      "You:mchne leangn\n",
      "Link: Neural Nets wiki\n",
      "You:hidden neurons\n",
      "Link: Neural Nets wiki\n",
      "You:details\n",
      "Link: Neural Nets wiki\n",
      "You:information\n",
      "Link: Neural Nets wiki\n",
      "You:quit\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy using Neural network is greater than that of Naive Bayes Classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
